{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm, trange\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport pytorch_lightning as pl\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nDATA_DIR = '/kaggle/input/plant-pathology-2020-fgvc7'\nSEED = 1279\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-28T05:29:23.576745Z","iopub.status.busy":"2022-05-28T05:29:23.576461Z","iopub.status.idle":"2022-05-28T05:29:23.581909Z","shell.execute_reply":"2022-05-28T05:29:23.581237Z","shell.execute_reply.started":"2022-05-28T05:29:23.576708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initial Data Analysis","metadata":{}},{"cell_type":"code","source":"!pip install ImageHash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\ntrain_df.rename(columns={'multiple_diseases': 'multi'}, inplace=True)\nto_drop = ['Train_379', 'Train_782', 'Train_1661'] # dropping repeated/mislabeled samples\ntrain_df = train_df[~train_df.image_id.isin(to_drop)]\ntest_df = pd.read_csv(f'{DATA_DIR}/test.csv')\nprint(train_df.head())\nprint(test_df.head())\nprint(type(train_df.iloc[0]))\nfor iterable in train_df.iloc[0].index:\n    print(iterable)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image display stuff\n\ndef disp(img_row):\n    img = Image.open(f\"{DATA_DIR}/images/{img_row['image_id']}.jpg\")\n    plt.figure()\n    plt.axis('off')\n    plt.title(', '.join([f'{lbl}={img_row[lbl]}' for lbl in img_row.index]))\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rusty_leaves = train_df[train_df['rust'] > 0]\nidxs = np.random.choice(len(rusty_leaves), size=10)\nfor idx in idxs:\n    disp(rusty_leaves.iloc[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scabby = train_df[train_df['scab'] > 0]\nidxs = np.random.choice(len(scabby), size=10)\nfor idx in idxs:\n    disp(scabby.iloc[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helth = train_df[train_df['healthy'] > 0]\nidxs = np.random.choice(len(helth), size=10)\nfor idx in idxs:\n    disp(helth.iloc[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = np.random.choice(len(test_df), size=10)\nfor i in idxs:\n    disp(test_df.iloc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking for similar images (https://github.com/JohannesBuchner/imagehash/blob/master/find_similar_images.py)\nimport imagehash\ndef find_similar_images(userpaths, hashfunc=imagehash.phash):\n    def is_image(filename):\n        f = filename.lower()\n        return f.endswith(\".png\") or f.endswith(\".jpg\") or \\\n            f.endswith(\".jpeg\") or f.endswith(\".bmp\") or \\\n            f.endswith(\".gif\") or '.jpg' in f or  f.endswith(\".svg\")\n    \n    image_filenames = []\n    for userpath in userpaths:\n        image_filenames += [os.path.join(userpath, path) for path in os.listdir(userpath) if is_image(path)]\n    images = {}\n    problematic = []\n    print(\"filenames obtained\")\n    for img in tqdm(sorted(image_filenames)):\n        try:\n            hash = hashfunc(Image.open(img))\n        except Exception as e:\n            print('Problem:', e, 'with', img)\n            continue\n        if hash in images:\n            print(img, '  already exists as', ' '.join(images[hash]))\n            problematic += [img, *images[hash]]\n#             if 'dupPictures' in img:\n#                 print('rm -v', img)\n        images[hash] = images.get(hash, []) + [img]\n    return problematic\n    \nproblematic = find_similar_images([f'{DATA_DIR}/images/'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(problematic)\npairs = []\nfor k in range(0,len(problematic),2):\n    pairs.append( (problematic[k].rsplit('/', 1)[-1], problematic[k+1].rsplit('/', 1)[-1]) )\nprint(pairs[-3:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = [379, 1173, 782, 592, 815, 1661]\nfor i in idxs:\n    disp(train_df.iloc[i])\n    \n# seems like we should drop Train_379, Train_782, and Train_1661","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['healthy', 'multi', 'rust', 'scab']:\n    print(f\"{col}, {sum(train_df[col])}\")\n    \n# data distribution: fairly even except for less multi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training\nNote: This is designed to be runnable even if the data analysis part is not run. As such, there's some code repeat.","metadata":{}},{"cell_type":"markdown","source":"### Data Setup","metadata":{}},{"cell_type":"code","source":"from torch.utils.data.dataset import Dataset, Subset\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.execute_input":"2022-05-28T05:29:28.315813Z","iopub.status.busy":"2022-05-28T05:29:28.315328Z","iopub.status.idle":"2022-05-28T05:29:28.320931Z","shell.execute_reply":"2022-05-28T05:29:28.320221Z","shell.execute_reply.started":"2022-05-28T05:29:28.315765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_data():\n    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n    train_df.rename(columns={'multiple_diseases': 'multi'}, inplace=True)\n    to_drop = ['Train_379', 'Train_782', 'Train_1661'] # dropping repeated/mislabeled samples\n    train_df = train_df[~train_df.image_id.isin(to_drop)]\n    files = [f\"{DATA_DIR}/images/{fname}.jpg\" for fname in train_df['image_id']]\n    labels = train_df.iloc[:, 1:].to_numpy().argmax(axis=1)\n    return files, labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_data():\n    test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n    files = [f\"{DATA_DIR}/images/{fname}.jpg\" for fname in test_df['image_id']]\n    return files","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(train=True):\n    transforms = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AppleDataset(Dataset):\n    def __init__(self, is_train, transforms):\n        self.transforms = transforms\n        self.is_train = is_train\n        if is_train:\n            self.filepaths, self.labels = get_train_data()\n        else:\n            self.filepaths = get_test_data()\n        \n    def __len__(self):\n        return len(self.filepaths)\n    \n    def __getitem__(self, i):\n        img = Image.open(self.filepaths[i]).convert('RGB')\n        img = self.transforms(img)\n        lbl = self.labels[i] if self.is_train else None\n        return (img, lbl)","metadata":{"execution":{"iopub.execute_input":"2022-05-28T05:29:34.562518Z","iopub.status.busy":"2022-05-28T05:29:34.562188Z","iopub.status.idle":"2022-05-28T05:29:34.573726Z","shell.execute_reply":"2022-05-28T05:29:34.571592Z","shell.execute_reply.started":"2022-05-28T05:29:34.562483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lightning folds !\nclass AppleKFoldDataModule(pl.LightningDataModule):\n    \n    def setup(self, stage=None):\n        transforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((224, 224)), # change this to some variable later!\n            torchvision.transforms.ToTensor()\n        ])\n        self.train_dset = AppleDataset(True, transforms)\n        self.test_dset = AppleDataset(False, transforms)\n    \n    def setup_folds(self, k_folds):\n        rng = np.random.default_rng(seed=SEED)\n        shuffled_idx = rng.permutation(len(self.train_dset))\n\n        self.splits = np.array_split(shuffled_idx, k_folds)\n        \n    def setup_fold_index(self, i):\n        train_idx = np.concatenate((self.splits[:i],self.splits[i+1:]))\n        val_idx = self.splits[i]\n        self.train_fold = Subset(self.train_dset, train_idx)\n        self.val_fold = Subset(self.train_dset, val_idx)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_fold, batch_size=32, shuffle=True) # change batch size for variable\n    \n    def val_dataloader(self):\n        return DataLoader(self.val_fold, batch_size=32, shuffle=True)\n        \n    def test_dataloader(self):\n        return DataLoader(self.test_dset, shuffle=True)\n    \n    def __post_init__(cls):\n        super().__init__()","metadata":{"execution":{"iopub.execute_input":"2022-05-28T05:29:48.491344Z","iopub.status.busy":"2022-05-28T05:29:48.491078Z","iopub.status.idle":"2022-05-28T05:29:48.501243Z","shell.execute_reply":"2022-05-28T05:29:48.500311Z","shell.execute_reply.started":"2022-05-28T05:29:48.491314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model(s) Setup","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.execute_input":"2022-05-28T06:04:27.538732Z","iopub.status.busy":"2022-05-28T06:04:27.538429Z","iopub.status.idle":"2022-05-28T06:04:27.542942Z","shell.execute_reply":"2022-05-28T06:04:27.54216Z","shell.execute_reply.started":"2022-05-28T06:04:27.538693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_base_model(model_name, pretrain=True):\n    if model_name == 'resnet-50':\n        model = torchvision.models.resnet50(pretrained=pretrain)\n        inp_size = 224\n        out_size = 1000\n        \n    return model, inp_size, out_size","metadata":{"execution":{"iopub.execute_input":"2022-05-28T06:04:28.68628Z","iopub.status.busy":"2022-05-28T06:04:28.686036Z","iopub.status.idle":"2022-05-28T06:04:28.690373Z","shell.execute_reply":"2022-05-28T06:04:28.689704Z","shell.execute_reply.started":"2022-05-28T06:04:28.686253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AppleModel(pl.LightningModule): #Lightning-fied\n    def __init__(self, base_model_name='resnet-50', out_classes=4):\n        super().__init__()\n        self.ft_extractor, self.inp_size, out_size = initialize_base_model(base_model_name, pretrain=True)\n        self.clfr = nn.Sequential(nn.Linear(out_size, out_classes), nn.Softmax(dim=1))\n        \n    def training_step(self, batch, batch_idx):\n        x,y = batch\n        x = self.ft_extractor(x)\n        out = self.clfr(x)\n        loss = F.nll_loss(out, y)\n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n        ","metadata":{"execution":{"iopub.execute_input":"2022-05-28T06:04:31.356133Z","iopub.status.busy":"2022-05-28T06:04:31.355454Z","iopub.status.idle":"2022-05-28T06:04:31.362682Z","shell.execute_reply":"2022-05-28T06:04:31.361954Z","shell.execute_reply.started":"2022-05-28T06:04:31.356098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset and Dataloader setup","metadata":{}},{"cell_type":"code","source":"# Lightning Train Loop\n\nmodel = AppleModel()\ndatamodule = AppleKFoldDataModule()\ntrainer = pl.Trainer(\n    limit_train_batches=32,\n    max_epochs=2)\ninternal_fit_loop = trainer.fit_loop\ntrainer.fit_loop = KFoldLoop(5, export_path=\"./\")\ntrainer.fit_loop.connect(internal_fit_loop)\ntrainer.fit(model, datamodule)","metadata":{"execution":{"iopub.execute_input":"2022-05-27T23:57:56.527117Z","iopub.status.busy":"2022-05-27T23:57:56.52683Z","iopub.status.idle":"2022-05-27T23:57:57.112932Z","shell.execute_reply":"2022-05-27T23:57:57.111333Z","shell.execute_reply.started":"2022-05-27T23:57:56.527087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AppleModel()\ntransforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((224, 224)), # change this to some variable later!\n            torchvision.transforms.ToTensor()\n])\ndatamodule = DataLoader(AppleDataset(True, transforms), batch_size=32, shuffle=True)\ntrainer = pl.Trainer(\n    max_epochs=2,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n)\ntrainer.fit(model, datamodule)","metadata":{"execution":{"iopub.execute_input":"2022-05-28T06:07:52.119143Z","iopub.status.busy":"2022-05-28T06:07:52.118635Z","iopub.status.idle":"2022-05-28T06:08:26.925199Z","shell.execute_reply":"2022-05-28T06:08:26.924464Z","shell.execute_reply.started":"2022-05-28T06:07:52.119105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor k in range(1):\n    curr_model = AppleModel()\n    train_files = np.concatenate(image_folds[:k] + image_folds[k+1:])\n    train_lbl = np.concatenate(label_folds[:k] + label_folds[k+1:])\n    val_files = image_folds[k]\n    val_lbl = label_folds[k]\n    run_train_loop(curr_model, train_files, train_lbl, val_files, val_lbl)\n    models.append(curr_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}