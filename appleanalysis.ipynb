{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm, trange\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nDATA_DIR = '/kaggle/input/plant-pathology-2020-fgvc7'\nSEED = 1279\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-21T02:03:33.289548Z","iopub.execute_input":"2022-06-21T02:03:33.291600Z","iopub.status.idle":"2022-06-21T02:03:33.318610Z","shell.execute_reply.started":"2022-06-21T02:03:33.291497Z","shell.execute_reply":"2022-06-21T02:03:33.317868Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Initial Data Analysis","metadata":{}},{"cell_type":"code","source":"# !pip install ImageHash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n# train_df.rename(columns={'multiple_diseases': 'multi'}, inplace=True)\n# to_drop = ['Train_379', 'Train_782', 'Train_1661'] # dropping repeated/mislabeled samples\n# train_df = train_df[~train_df.image_id.isin(to_drop)]\n# test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n# print(train_df.head())\n# print(test_df.head())\n# print(type(train_df.iloc[0]))\n# for iterable in train_df.iloc[0].index:\n#     print(iterable)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T05:10:52.645846Z","iopub.execute_input":"2022-06-19T05:10:52.646117Z","iopub.status.idle":"2022-06-19T05:10:52.670003Z","shell.execute_reply.started":"2022-06-19T05:10:52.646087Z","shell.execute_reply":"2022-06-19T05:10:52.669141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image display stuff\n\ndef disp(img_row):\n    img = Image.open(f\"{DATA_DIR}/images/{img_row['image_id']}.jpg\")\n    plt.figure()\n    plt.axis('off')\n    plt.title(', '.join([f'{lbl}={img_row[lbl]}' for lbl in img_row.index]))\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T04:51:51.318641Z","iopub.execute_input":"2022-06-19T04:51:51.319159Z","iopub.status.idle":"2022-06-19T04:51:51.324126Z","shell.execute_reply.started":"2022-06-19T04:51:51.319124Z","shell.execute_reply":"2022-06-19T04:51:51.323355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rusty_leaves = train_df[train_df['rust'] > 0]\nidxs = np.random.choice(len(rusty_leaves), size=10)\nfor idx in idxs:\n    disp(rusty_leaves.iloc[idx])","metadata":{"execution":{"iopub.status.busy":"2022-06-19T05:10:55.270186Z","iopub.execute_input":"2022-06-19T05:10:55.270773Z","iopub.status.idle":"2022-06-19T05:10:59.831999Z","shell.execute_reply.started":"2022-06-19T05:10:55.270737Z","shell.execute_reply":"2022-06-19T05:10:59.831145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scabby = train_df[train_df['scab'] > 0]\n# idxs = np.random.choice(len(scabby), size=10)\n# for idx in idxs:\n#     disp(scabby.iloc[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helth = train_df[train_df['healthy'] > 0]\n# idxs = np.random.choice(len(helth), size=10)\n# for idx in idxs:\n#     disp(helth.iloc[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idxs = np.random.choice(len(test_df), size=10)\n# for i in idxs:\n#     disp(test_df.iloc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # looking for similar images (https://github.com/JohannesBuchner/imagehash/blob/master/find_similar_images.py)\n# import imagehash\n# def find_similar_images(userpaths, hashfunc=imagehash.phash):\n#     def is_image(filename):\n#         f = filename.lower()\n#         return f.endswith(\".png\") or f.endswith(\".jpg\") or \\\n#             f.endswith(\".jpeg\") or f.endswith(\".bmp\") or \\\n#             f.endswith(\".gif\") or '.jpg' in f or  f.endswith(\".svg\")\n    \n#     image_filenames = []\n#     for userpath in userpaths:\n#         image_filenames += [os.path.join(userpath, path) for path in os.listdir(userpath) if is_image(path)]\n#     images = {}\n#     problematic = []\n#     print(\"filenames obtained\")\n#     for img in tqdm(sorted(image_filenames)):\n#         try:\n#             hash = hashfunc(Image.open(img))\n#         except Exception as e:\n#             print('Problem:', e, 'with', img)\n#             continue\n#         if hash in images:\n#             print(img, '  already exists as', ' '.join(images[hash]))\n#             problematic += [img, *images[hash]]\n# #             if 'dupPictures' in img:\n# #                 print('rm -v', img)\n#         images[hash] = images.get(hash, []) + [img]\n#     return problematic\n    \n# problematic = find_similar_images([f'{DATA_DIR}/images/'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # print(problematic)\n# pairs = []\n# for k in range(0,len(problematic),2):\n#     pairs.append( (problematic[k].rsplit('/', 1)[-1], problematic[k+1].rsplit('/', 1)[-1]) )\n# print(pairs[-3:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idxs = [379, 1173, 782, 592, 815, 1661]\n# for i in idxs:\n#     disp(train_df.iloc[i])\n    \n# # seems like we should drop Train_379, Train_782, and Train_1661","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for col in ['healthy', 'multi', 'rust', 'scab']:\n#     print(f\"{col}, {sum(train_df[col])}\")\n    \n# # data distribution: fairly even except for less multi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training\nNote: This is designed to be runnable even if the data analysis part is not run. As such, there's some code repeat.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data.dataset import Dataset, Subset\nfrom torch.utils.data import DataLoader\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:08:25.373367Z","iopub.execute_input":"2022-06-19T08:08:25.374434Z","iopub.status.idle":"2022-06-19T08:08:35.320978Z","shell.execute_reply.started":"2022-06-19T08:08:25.374395Z","shell.execute_reply":"2022-06-19T08:08:35.320193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility Functions","metadata":{}},{"cell_type":"code","source":"def get_train_data():\n    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n    train_df.rename(columns={'multiple_diseases': 'multi'}, inplace=True)\n    to_drop = ['Train_379', 'Train_782', 'Train_1661'] # dropping repeated/mislabeled samples\n    train_df = train_df[~train_df.image_id.isin(to_drop)]\n    files = [f\"{DATA_DIR}/images/{fname}.jpg\" for fname in train_df['image_id']]\n    labels = train_df.iloc[:, 1:].to_numpy().argmax(axis=1).astype(int)\n    return files, labels","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:08:56.098925Z","iopub.execute_input":"2022-06-19T08:08:56.099202Z","iopub.status.idle":"2022-06-19T08:08:56.105535Z","shell.execute_reply.started":"2022-06-19T08:08:56.099172Z","shell.execute_reply":"2022-06-19T08:08:56.104500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_data():\n    test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n    files = [f\"{DATA_DIR}/images/{fname}.jpg\" for fname in test_df['image_id']]\n    return files, None","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:08:58.407006Z","iopub.execute_input":"2022-06-19T08:08:58.407613Z","iopub.status.idle":"2022-06-19T08:08:58.412338Z","shell.execute_reply.started":"2022-06-19T08:08:58.407572Z","shell.execute_reply":"2022-06-19T08:08:58.411305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(train=True):\n    transforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((224, 224)), # change this to some variable later!\n            torchvision.transforms.ToTensor()\n    ])\n    return transforms","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:08:59.004655Z","iopub.execute_input":"2022-06-19T08:08:59.005149Z","iopub.status.idle":"2022-06-19T08:08:59.010571Z","shell.execute_reply.started":"2022-06-19T08:08:59.005099Z","shell.execute_reply":"2022-06-19T08:08:59.008819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_acc(outputs, labels):\n    return np.mean(outputs==labels)\n\ndef compute_mean_auc(outputs, labels):\n    return roc_auc_score(labels, outputs, average='macro', multi_class='ovr')","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:08:59.643118Z","iopub.execute_input":"2022-06-19T08:08:59.643677Z","iopub.status.idle":"2022-06-19T08:08:59.648093Z","shell.execute_reply.started":"2022-06-19T08:08:59.643636Z","shell.execute_reply":"2022-06-19T08:08:59.647400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset and Dataloader setup","metadata":{}},{"cell_type":"code","source":"class AppleDataset(Dataset):\n    def __init__(self, filepaths, transforms, labels=None):\n        self.transforms = transforms\n        self.filepaths = filepaths\n        self.labels = labels\n        \n    def __len__(self):\n        return len(self.filepaths)\n    \n    def __getitem__(self, i):\n        img = Image.open(self.filepaths[i]).convert('RGB')\n        img = self.transforms(img)\n        lbl = self.labels[i] if self.labels is not None else None\n        return (img, lbl)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:08.057315Z","iopub.execute_input":"2022-06-19T08:09:08.057834Z","iopub.status.idle":"2022-06-19T08:09:08.064513Z","shell.execute_reply.started":"2022-06-19T08:09:08.057796Z","shell.execute_reply":"2022-06-19T08:09:08.062871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lightning folds !\nclass AppleKFoldDataModule(pl.LightningDataModule):\n    def __init__(self, k_folds=5):\n        self.k_folds = k_folds\n        super().__init__()\n    \n    def setup(self, stage=None):\n        transforms = get_transforms()\n        train_files, train_labels = get_train_data()\n        test_files = get_test_data()\n        self.train_dset = AppleDataset(train_files, transforms, labels=train_labels)\n        self.test_dset = AppleDataset(test_files, transforms)\n    \n    def setup_folds(self):\n        rng = np.random.default_rng(seed=SEED)\n        shuffled_idx = rng.permutation(len(self.train_dset))\n        self.splits = np.array_split(shuffled_idx, self.k_folds)\n        \n    def setup_fold_index(self, i):\n        train_idx = np.concatenate(self.splits[:i] + self.splits[i+1:])\n        val_idx = self.splits[i]\n        self.train_fold = Subset(self.train_dset, train_idx)\n        self.val_fold = Subset(self.train_dset, val_idx)\n    \n    def train_dataloader(self, bsz=32):\n        return DataLoader(self.train_fold, batch_size=bsz, shuffle=True) # change batch size for variable\n    \n    def val_dataloader(self, bsz=32):\n        return DataLoader(self.val_fold, batch_size=bsz, shuffle=False)\n        \n    def test_dataloader(self, bsz=32):\n        return DataLoader(self.test_dset, batch_size=bsz, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:09.644095Z","iopub.execute_input":"2022-06-19T08:09:09.644612Z","iopub.status.idle":"2022-06-19T08:09:09.654964Z","shell.execute_reply.started":"2022-06-19T08:09:09.644575Z","shell.execute_reply":"2022-06-19T08:09:09.653622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model(s) Setup","metadata":{}},{"cell_type":"code","source":"def initialize_base_model(model_name, pretrain=True):\n    if model_name == 'resnet-50':\n        model = torchvision.models.resnet50(pretrained=pretrain)\n        inp_size = 224\n        out_size = 1000\n        \n    return model, inp_size, out_size","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:12.084335Z","iopub.execute_input":"2022-06-19T08:09:12.084876Z","iopub.status.idle":"2022-06-19T08:09:12.091052Z","shell.execute_reply.started":"2022-06-19T08:09:12.084836Z","shell.execute_reply":"2022-06-19T08:09:12.089096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GenericAppleArch(nn.Module):\n    def __init__(self, base_model_name='resnet-50', out_classes=4):\n        super(GenericAppleArch, self).__init__()\n        self.ft_extractor, self.inp_size, out_size = initialize_base_model(base_model_name, pretrain=True)\n        self.clfr = nn.Sequential(nn.Linear(out_size, out_classes), nn.Softmax(dim=1))\n        \n    def forward(self, x):\n        x = self.ft_extractor(x)\n        out = self.clfr(x)\n        return out\n    \n\nclass AppleModel(pl.LightningModule): #Lightning-fied\n    def __init__(self, base_model_name='resnet-50', out_classes=4, lr=1e-5):\n        super().__init__()\n        self.model = GenericAppleArch(base_model_name=base_model_name, out_classes=out_classes)\n        self.lr = lr\n        self.save_hyperparameters()\n        self.xvals = []\n        \n    def on_train_epoch_start(self):\n        self.train_outputs = []\n        self.train_ys = []\n    \n    def on_validation_epoch_start(self):\n        self.val_outputs = []\n        self.val_ys = []\n        \n    def training_step(self, batch, batch_idx):\n        x,y = batch\n        out = self.model(x)\n        loss = F.nll_loss(out, y)\n        self.train_outputs += list(out.detach().cpu().numpy())\n        self.train_ys += list(y.detach().cpu())\n        self.log('train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x,y = batch\n        out = self.model(x)\n        self.val_outputs += list(out.detach().cpu().numpy())\n        self.val_ys += list(y.detach().cpu().numpy())\n        loss = F.nll_loss(out, y)\n        self.log('val_loss', loss)\n    \n    def error_check_step(self, batch, batch_idx): # for seeing wrong answers\n        x,y = batch\n        out = self.model(x)\n        self.val_outputs += list(out.detach().cpu().numpy())\n        self.val_ys += list(y.detach().cpu().numpy())\n        self.xvals += list(x.detach().cpu().numpy())\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        return optimizer\n    \n    def on_train_epoch_end(self):\n        all_outputs = np.array(self.train_outputs)\n        all_preds = np.argmax(all_outputs, axis=1)\n        all_ys = np.array(self.train_ys)\n        epoch_acc = compute_acc(all_preds, all_ys)\n        mean_auc = compute_mean_auc(all_outputs, all_ys)\n        self.log_dict({'train_acc': epoch_acc, 'train_mean_auc': mean_auc})\n        print(f\"Train acc={epoch_acc}\")\n        print(f\"Train mean auc={mean_auc}\")\n    \n    def on_validation_epoch_end(self):\n        all_outputs = np.array(self.val_outputs)\n        all_preds = np.argmax(all_outputs, axis=1)\n        all_ys = np.array(self.val_ys)\n        epoch_acc = compute_acc(all_preds, all_ys)\n        mean_auc = compute_mean_auc(all_outputs, all_ys)\n        self.log_dict({'val_acc': epoch_acc, 'val_mean_auc': mean_auc})\n        print(f\"Val acc={epoch_acc}\")\n        print(f\"Val mean auc={mean_auc}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:12.685829Z","iopub.execute_input":"2022-06-19T08:09:12.686433Z","iopub.status.idle":"2022-06-19T08:09:12.707642Z","shell.execute_reply.started":"2022-06-19T08:09:12.686396Z","shell.execute_reply":"2022-06-19T08:09:12.706899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"from copy import deepcopy\nfrom datetime import datetime\nfrom pytz import timezone\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:16.530685Z","iopub.execute_input":"2022-06-19T08:09:16.530988Z","iopub.status.idle":"2022-06-19T08:09:16.535742Z","shell.execute_reply.started":"2022-06-19T08:09:16.530956Z","shell.execute_reply":"2022-06-19T08:09:16.535103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## WANDB\n# https://wandb.ai/manan-goel/MNIST/reports/How-to-Integrate-PyTorch-Lightning-with-Weights-Biases--VmlldzoxNjg1ODQ1\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger\nfrom kaggle_secrets import UserSecretsClient\nimport os\nuser_secrets = UserSecretsClient()\nos.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"wandbKey\")","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:17.260077Z","iopub.execute_input":"2022-06-19T08:09:17.260894Z","iopub.status.idle":"2022-06-19T08:09:17.724078Z","shell.execute_reply.started":"2022-06-19T08:09:17.260844Z","shell.execute_reply":"2022-06-19T08:09:17.722978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(SEED)\nexp_name = \"baseline\"\ntry:\n    wandb.finish()\nexcept:\n    pass\nk_models = []\nconfig = {\n    'trainer_kwargs': \n        {\n            'max_epochs': 30,\n            'accelerator': \"gpu\" if torch.cuda.is_available() else \"cpu\",\n            'default_root_dir': \"/kaggle/working/\",\n            'auto_lr_find': False,\n            'log_every_n_steps': 10,\n        },\n    'model_kwargs':\n        {\n            'base_model_name': 'resnet-50', \n            'out_classes': 4,\n            'lr': 1e-5\n        }\n}\ndm = AppleKFoldDataModule(k_folds=5)\ndm.prepare_data()\ndm.setup()\ndm.setup_folds()\nmodel = AppleModel()\nbase_state_dict = model.state_dict()\nfor k in range(dm.k_folds):\n    time = datetime.now(timezone('US/Pacific')).strftime(\"%m_%d-h%H_m%M\")\n    save_filepath = f\"{exp_name}-fold{k+1}of{dm.k_folds}-{time}\"\n    config['trainer_kwargs']['logger'] = WandbLogger(project=\"apple-kaggle\", entity=\"waggle\", name=f\"{exp_name}_fold{k+1}of{dm.k_folds}\")\n    config['trainer_kwargs']['callbacks'] = [\n        EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n        checkpoint_callback = ModelCheckpoint(dirpath=\"/kaggle/working/\", save_top_k=1, monitor=\"val_loss\", filename=save_filepath)\n    ]\n    trainer = pl.Trainer(**config['trainer_kwargs'])\n    dm.setup_fold_index(k)\n    model.load_state_dict(base_state_dict)\n    trainer.fit(model, datamodule=dm)\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T19:42:04.360739Z","iopub.execute_input":"2022-06-17T19:42:04.361083Z","iopub.status.idle":"2022-06-17T21:22:03.724622Z","shell.execute_reply.started":"2022-06-17T19:42:04.361038Z","shell.execute_reply":"2022-06-17T21:22:03.723848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:32:17.782968Z","iopub.execute_input":"2022-06-11T22:32:17.783234Z","iopub.status.idle":"2022-06-11T22:32:17.849225Z","shell.execute_reply.started":"2022-06-11T22:32:17.783202Z","shell.execute_reply":"2022-06-11T22:32:17.848137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Analysis\nTesting results of completed models","metadata":{}},{"cell_type":"code","source":"# input_model_name = \"baseline-fold4of5-06_18-h10_m19.ckpt\"\niput_model_name = '../input/v65apple/baseline-fold4of5-06_18-h10_m19.ckpt'\n# model_path = f\"/kaggle/input/appleanalysis/{input_model_name}\"\nmodel_path = \"/kaggle/input/v65apple/baseline-fold4of5-06_18-h10_m19.ckpt\"\nckpt = torch.load(model_path)\n# old_model = AppleModel(**ckpt['hyper_parameters'])\nold_model = AppleModel.load_from_checkpoint(model_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:09:31.106777Z","iopub.execute_input":"2022-06-19T08:09:31.107093Z","iopub.status.idle":"2022-06-19T08:09:44.878224Z","shell.execute_reply.started":"2022-06-19T08:09:31.107058Z","shell.execute_reply":"2022-06-19T08:09:44.877275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(SEED)\ndm = AppleKFoldDataModule(k_folds=5)\ndm.prepare_data()\ndm.setup()\ndm.setup_folds()\ndm.setup_fold_index(4)\ndl = dm.val_dataloader()\nprint('hey')\n\nold_model.eval()\nold_model.on_validation_epoch_start()\nfor i, (x,y) in tqdm(enumerate(dl)):\n    old_model.error_check_step((x,y), i)\n    \noutputs = old_model.val_outputs\nlabels = old_model.val_ys\nxvals = old_model.xvals\nprint(outputs[0])\nprint(labels[0])\nprint(xvals[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:11:48.507010Z","iopub.execute_input":"2022-06-19T08:11:48.507579Z","iopub.status.idle":"2022-06-19T08:12:47.823131Z","shell.execute_reply.started":"2022-06-19T08:11:48.507540Z","shell.execute_reply":"2022-06-19T08:12:47.822189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.argmax(outputs[0]))\nprint(outputs[0])\nprint(labels[0])\nprint(xvals[0].shape)\nplt.imshow(xvals[0].transpose(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:37:27.090064Z","iopub.execute_input":"2022-06-19T08:37:27.090338Z","iopub.status.idle":"2022-06-19T08:37:27.313592Z","shell.execute_reply.started":"2022-06-19T08:37:27.090310Z","shell.execute_reply":"2022-06-19T08:37:27.312911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get all errors\nerrors = []\nfor i in range(len(labels)):\n    if labels[i] != np.argmax(outputs[i]):\n        errors.append((outputs[i], labels[i], xvals[i].transpose(1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:39:07.434352Z","iopub.execute_input":"2022-06-19T08:39:07.434673Z","iopub.status.idle":"2022-06-19T08:39:07.443788Z","shell.execute_reply.started":"2022-06-19T08:39:07.434636Z","shell.execute_reply":"2022-06-19T08:39:07.443004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_error(ind):\n    out, label, img = errors[ind]\n    print(out)\n    print(label)\n    plt.imshow(img)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:44:18.909455Z","iopub.execute_input":"2022-06-19T08:44:18.909717Z","iopub.status.idle":"2022-06-19T08:44:18.914217Z","shell.execute_reply.started":"2022-06-19T08:44:18.909689Z","shell.execute_reply":"2022-06-19T08:44:18.913189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(errors)):\n    display_error(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T08:44:21.043190Z","iopub.execute_input":"2022-06-19T08:44:21.043664Z","iopub.status.idle":"2022-06-19T08:44:22.423617Z","shell.execute_reply.started":"2022-06-19T08:44:21.043627Z","shell.execute_reply":"2022-06-19T08:44:22.422970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}